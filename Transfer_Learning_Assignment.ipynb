{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/karanidenis/transfer_learning_assignment/blob/main/Transfer_Learning_Assignment.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "-CTgbf2KZvF5"
      },
      "outputs": [],
      "source": [
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from keras.utils import to_categorical\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "# from tensorflow.keras.losses import categorical_crossentropy\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tensorflow.keras.applications import VGG16, ResNet50, InceptionV3\n",
        "from tensorflow.keras import layers, models\n",
        "# from keras.losses import categorical_crossentropy\n",
        "from tensorflow.keras.layers import Dense, GlobalAveragePooling2D\n",
        "from tensorflow.keras.models import Model\n",
        "from skimage.transform import resize"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "8dl-xB-0oVeT"
      },
      "outputs": [],
      "source": [
        "IMG_ROWS = 224\n",
        "IMG_COLS = 224\n",
        "NUM_CLASSES = 10\n",
        "TEST_SIZE = 0.2\n",
        "RANDOM_STATE = 2018\n",
        "NO_EPOCHS = 10\n",
        "BATCH_SIZE = 128\n",
        "\n",
        "learning_rate = 0.001\n",
        "\n",
        "# Load pre-trained models\n",
        "base_models = [VGG16, ResNet50, InceptionV3]\n",
        "models = []"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for base_model in base_models:\n",
        "    base = base_model(weights='imagenet', include_top=False, input_shape=(IMG_ROWS, IMG_COLS, 3))\n",
        "    x = base.output\n",
        "    x = GlobalAveragePooling2D()(x)\n",
        "    x = Dense(1, activation='relu')(x)\n",
        "    predictions = Dense(NUM_CLASSES, activation='softmax')(x)\n",
        "    model = Model(inputs=base.input, outputs=predictions)\n",
        "    models.append(model)"
      ],
      "metadata": {
        "id": "GHYSAY1DRlYF"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Freeze pre-trained layers\n",
        "for model in models:\n",
        "    for layer in model.layers[:-2]:\n",
        "        layer.trainable = False\n",
        "\n",
        "# Compile models\n",
        "for model in models:\n",
        "    model.compile(optimizer=Adam(lr=learning_rate), loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "    # model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-hkRCftHvUUU",
        "outputId": "d570acee-b2f7-4399-8b8c-2e2c2ccd942c"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n",
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n",
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# train_file = \"fashion-mnist_train.csv\"\n",
        "train_file = \"/content/drive/MyDrive/Colab Notebooks/fashion-mnist_train.csv\"\n",
        "# test_file  = \"fashion-mnist_test.csv\"\n",
        "test_file = \"/content/drive/MyDrive/Colab Notebooks/fashion-mnist_test.csv\"\n",
        "\n",
        "train_data = pd.read_csv(train_file)\n",
        "test_data = pd.read_csv(test_file)\n",
        "\n",
        "print(\"Fashion MNIST train -  rows:\",train_data.shape[0],\" columns:\", train_data.shape[1])\n",
        "print(\"Fashion MNIST test -  rows:\",test_data.shape[0],\" columns:\", test_data.shape[1])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iK_GzKjUNuge",
        "outputId": "fb6e1cb2-d2ab-4972-ede7-5981950acd33"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fashion MNIST train -  rows: 60000  columns: 785\n",
            "Fashion MNIST test -  rows: 10000  columns: 785\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a dictionary for each type of label\n",
        "labels = {0 : \"T-shirt/top\", 1: \"Trouser\", 2: \"Pullover\", 3: \"Dress\", 4: \"Coat\",\n",
        "          5: \"Sandal\", 6: \"Shirt\", 7: \"Sneaker\", 8: \"Bag\", 9: \"Ankle Boot\"}\n",
        "\n",
        "def get_classes_distribution(data):\n",
        "    # Get the count for each label\n",
        "    label_counts = data[\"label\"].value_counts()\n",
        "\n",
        "    # Get total number of samples\n",
        "    total_samples = len(data)\n",
        "\n",
        "\n",
        "    # Count the number of items in each class\n",
        "    for i in range(len(label_counts)):\n",
        "        label = labels[label_counts.index[i]]\n",
        "        count = label_counts.values[i]\n",
        "        percent = (count / total_samples) * 100\n",
        "        print(\"{:<20s}:   {} or {}%\".format(label, count, percent))\n",
        "\n",
        "get_classes_distribution(train_data)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s69tTjSpPgmc",
        "outputId": "7e33c91e-5ce3-4911-c5bd-e58a38ebf04c"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Pullover            :   6000 or 10.0%\n",
            "Ankle Boot          :   6000 or 10.0%\n",
            "Shirt               :   6000 or 10.0%\n",
            "T-shirt/top         :   6000 or 10.0%\n",
            "Dress               :   6000 or 10.0%\n",
            "Coat                :   6000 or 10.0%\n",
            "Sandal              :   6000 or 10.0%\n",
            "Bag                 :   6000 or 10.0%\n",
            "Sneaker             :   6000 or 10.0%\n",
            "Trouser             :   6000 or 10.0%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def data_preprocessing(raw):\n",
        "    # Convert labels to one-hot encoded vectors\n",
        "    out_y = to_categorical(raw.label, NUM_CLASSES)\n",
        "    num_images = raw.shape[0]\n",
        "    x_as_array = raw.iloc[:, 1:].values.astype('float32')\n",
        "    x_rgb_array = np.repeat(x_as_array.reshape(num_images, 28, 28, 1), 3, axis=-1)  # Resize to 3 channels\n",
        "    x_resized = np.array([resize(img, (IMG_ROWS, IMG_COLS)) for img in x_rgb_array])  # Resize images\n",
        "    out_x = x_resized / 255.0\n",
        "    return out_x, out_y\n",
        "\n",
        "\n",
        "# def data_preprocessing(raw):\n",
        "#     out_y = to_categorical(raw.label, NUM_CLASSES)\n",
        "#     num_images = raw.shape[0]\n",
        "#     x_as_array = raw.values[:,1:]\n",
        "#     # Convert grayscale images to RGB by duplicating the single channel\n",
        "#     x_rgb_array = np.repeat(x_as_array.reshape(num_images, IMG_ROWS, IMG_COLS, 1), 3, axis=-1)\n",
        "#     out_x = x_rgb_array / 255\n",
        "#     return out_x, out_y\n"
      ],
      "metadata": {
        "id": "RiHWz7SXPvqC"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X, y = data_preprocessing(train_data)\n",
        "X_test, y_test = data_preprocessing(test_data)"
      ],
      "metadata": {
        "id": "hHtxJzVOQAm7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=TEST_SIZE, random_state=RANDOM_STATE)"
      ],
      "metadata": {
        "collapsed": true,
        "id": "DMZe_nzUQFid"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Fashion MNIST train -  rows:\",X_train.shape[0],\" columns:\", X_train.shape[1:4])\n",
        "print(\"Fashion MNIST valid -  rows:\",X_val.shape[0],\" columns:\", X_val.shape[1:4])\n",
        "# print(\"Fashion MNIST test -  rows:\",X_test.shape[0],\" columns:\", X_test.shape[1:4])\n",
        "print(y_train.shape)"
      ],
      "metadata": {
        "id": "OHxyhaUQQHGa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_model = model.fit(X_train, y_train,\n",
        "                  batch_size=BATCH_SIZE,\n",
        "                  epochs=NO_EPOCHS,\n",
        "                  verbose=1,\n",
        "                  validation_data=(X_val, y_val))"
      ],
      "metadata": {
        "id": "QR_vdu32cS69"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Training the model\n",
        "history = model.fit(X_train, y_train,\n",
        "                    batch_size=BATCH_SIZE,\n",
        "                    epochs=NO_EPOCHS,\n",
        "                    verbose=1,\n",
        "                    validation_data=(X_val, y_val))\n",
        "\n",
        "\n",
        "\n",
        "# Evaluate the model on test data\n",
        "score = model.evaluate(X_test, y_test, verbose=0)\n",
        "print('Test loss:', score[0])\n",
        "print('Test accuracy:', score[1])\n",
        "\n",
        "# Plot training history\n",
        "plt.figure(figsize=(12, 6))\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.plot(history.history['accuracy'], label='Training Accuracy')\n",
        "plt.plot(history.history['val_accuracy'], label='Validation Accuracy')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.legend()\n",
        "plt.title('Training and Validation Accuracy')\n",
        "\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.plot(history.history['loss'], label='Training Loss')\n",
        "plt.plot(history.history['val_loss'], label='Validation Loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend()\n",
        "plt.title('Training and Validation Loss')\n",
        "plt.show()\n",
        "\n"
      ],
      "metadata": {
        "id": "Gytikg_QrHwl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "IMG_ROWS = 224\n",
        "IMG_COLS = 224\n",
        "NUM_CLASSES = 10\n",
        "TEST_SIZE = 0.2\n",
        "RANDOM_STATE = 2018\n",
        "NO_EPOCHS = 10\n",
        "BATCH_SIZE = 128\n",
        "\n",
        "learning_rate = 0.001\n",
        "\n",
        "# Load pre-trained models\n",
        "base_models = [VGG16, ResNet50, InceptionV3]\n",
        "models = []\n",
        "\n",
        "for base_model in base_models:\n",
        "    base = base_model(weights='imagenet', include_top=False, input_shape=(IMG_ROWS, IMG_COLS, 3))\n",
        "    x = base.output\n",
        "    x = GlobalAveragePooling2D()(x)\n",
        "    x = Dense(1, activation='relu')(x)\n",
        "    predictions = Dense(NUM_CLASSES, activation='softmax')(x)\n",
        "    model = Model(inputs=base.input, outputs=predictions)\n",
        "    models.append(model)\n",
        "\n",
        "# Freeze pre-trained layers\n",
        "for model in models:\n",
        "    for layer in model.layers[:-2]:\n",
        "        layer.trainable = False\n",
        "\n",
        "# Compile models\n",
        "for model in models:\n",
        "    model.compile(optimizer=Adam(lr=learning_rate), loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# train_file = \"fashion-mnist_train.csv\"\n",
        "train_file = \"/content/drive/MyDrive/Colab Notebooks/fashion-mnist_train.csv\"\n",
        "# test_file  = \"fashion-mnist_test.csv\"\n",
        "test_file = \"/content/drive/MyDrive/Colab Notebooks/fashion-mnist_test.csv\"\n",
        "\n",
        "train_data = pd.read_csv(train_file)\n",
        "test_data = pd.read_csv(test_file)\n",
        "\n",
        "print(\"Fashion MNIST train -  rows:\",train_data.shape[0],\" columns:\", train_data.shape[1])\n",
        "print(\"Fashion MNIST test -  rows:\",test_data.shape[0],\" columns:\", test_data.shape[1])\n",
        "\n",
        "def data_preprocessing(raw):\n",
        "    # Convert labels to one-hot encoded vectors\n",
        "    out_y = to_categorical(raw.label, NUM_CLASSES)\n",
        "\n",
        "    # Reshape input images to the desired shape and normalize pixel values\n",
        "    num_images = raw.shape[0]\n",
        "    x_as_array = raw.iloc[:, 1:].values.astype('float32')  # Extract pixel values\n",
        "\n",
        "    # Convert grayscale images to RGB by duplicating the single channel\n",
        "    x_rgb_array = np.repeat(x_as_array.reshape(num_images, IMG_ROWS, IMG_COLS, 1), 3, axis=-1)\n",
        "\n",
        "    out_x = x_rgb_array / 255.0\n",
        "\n",
        "    return out_x, out_y\n",
        "\n",
        "X, y = data_preprocessing(train_data)\n",
        "X_test, y_test = data_preprocessing(test_data)\n",
        "\n",
        "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=TEST_SIZE, random_state=RANDOM_STATE)\n",
        "\n",
        "print(\"Fashion MNIST train -  rows:\",X_train.shape[0],\" columns:\", X_train.shape[1:4])\n",
        "print(\"Fashion MNIST valid -  rows:\",X_val.shape[0],\" columns:\", X_val.shape[1:4])\n",
        "# print(\"Fashion MNIST test -  rows:\",X_test.shape[0],\" columns:\", X_test.shape[1:4])\n",
        "print(y_train.shape)\n",
        "\n",
        "train_model = model.fit(X_train, y_train,\n",
        "                  batch_size=BATCH_SIZE,\n",
        "                  epochs=NO_EPOCHS,\n",
        "                  verbose=1,\n",
        "                  validation_data=(X_val, y_val))"
      ],
      "metadata": {
        "id": "8z8cLjcx3n6n"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "126qpkrTGnEarWgw99XqZ-iIXHqrZJYhJ",
      "authorship_tag": "ABX9TyPQYr1Mu02OjxnUYZsFFOzs",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}